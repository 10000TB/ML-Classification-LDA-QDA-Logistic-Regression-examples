{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    "\\newcommand{\\Xv}{\\mathbf{X}}\n",
    "\\newcommand{\\yv}{\\mathbf{y}}\n",
    "\\newcommand{\\zv}{\\mathbf{z}}\n",
    "\\newcommand{\\av}{\\mathbf{a}}\n",
    "\\newcommand{\\Wv}{\\mathbf{W}}\n",
    "\\newcommand{\\wv}{\\mathbf{w}}\n",
    "\\newcommand{\\tv}{\\mathbf{t}}\n",
    "\\newcommand{\\Tv}{\\mathbf{T}}\n",
    "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
    "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Classification with LDA, QDA, and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Xuehao(David) Hu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare LDA, QDA, and linear and nonlinear logistic regression applied to two data sets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download [nn2.tar](http://www.cs.colostate.edu/~anderson/cs480/notebooks/nn2.tar) and extract its contents, which are\n",
    "\n",
    "* `neuralnetworks.py`\n",
    "* `scaledconjugategradient.py`\n",
    "* `mlutils.py`\n",
    "* `qdalda.py`\n",
    "\n",
    "as discussed in lecture. \n",
    "\n",
    "Write the following functions that train and evaluate LDA, QDA, and neural network logistic regression models.\n",
    "\n",
    "* `model = trainLDA(X,T,parameters)`\n",
    "* `percentCorrect = evaluateLDA(model,X,T)`\n",
    "* `model = trainQDA(X,T,parameters)`\n",
    "* `percentCorrect = evaluateQDA(model,X,T)`\n",
    "* `model = trainNN(X,T,parameters)`\n",
    "* `percentCorrect = evaluateNN(model,X,T)`\n",
    "The `parameters` argument for `trainNN` is a list of the hidden layers structure and the number of SCG iterations, as in the previous assignment. The value of the `parameters` argument for `trainLDA` and `trainQDA` are not used.\n",
    "\n",
    "Use the `trainValidateTestKFoldsClassification` function in `mlutils.py` to apply the above functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlutils as ml\n",
    "import neuralnetworks as nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainLDA(X,T,parameters):\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluateLDA(model,X,T):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainQDA(X,T,parameters):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateQDA(model,X,T):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateQDA(model,X,T):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNN(X,T,parameters):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateNN(model,X,T):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#   To run this notebook, I import my solution\n",
    "# from A4mysolution import * \n",
    "#   You should include all function definitions that you need in this notebook.  They all do not \n",
    "#   have to be in the same code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example, using our automobile MPG data.  This time, instead of predicting the actual MPG values, we quantize the MPG values into 5 intervals, and classify each sample as being in one of these 5 intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeMPGData(filename='auto-mpg.data'):\n",
    "    def missingIsNan(s):\n",
    "        return np.nan if s == b'?' else float(s)\n",
    "    data = np.loadtxt(filename, usecols=range(8), converters={3: missingIsNan})\n",
    "    print(\"Read\",data.shape[0],\"rows and\",data.shape[1],\"columns from\",filename)\n",
    "    goodRowsMask = np.isnan(data).sum(axis=1) == 0\n",
    "    data = data[goodRowsMask,:]\n",
    "    print(\"After removing rows containing question marks, data has\",data.shape[0],\"rows and\",data.shape[1],\"columns.\")\n",
    "    X = data[:,1:]\n",
    "    T = data[:,0:1]\n",
    "    Xnames =  ['cylinders','displacement','horsepower','weight','acceleration','year','origin']\n",
    "    Tname = 'mpg'\n",
    "    return X,T,Xnames,Tname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeMPGClasses(T):\n",
    "    bounds = np.arange(5,45,10)\n",
    "    Tclasses = -np.ones(T.shape).astype(np.int)\n",
    "    for i,mpg in enumerate(T):\n",
    "        for k in range(len(bounds)-1):\n",
    "            if bounds[k] < mpg <= bounds[k+1]:\n",
    "                Tclasses[i] = bounds[k+1]\n",
    "        if Tclasses[i] == -1:\n",
    "            Tclasses[i] = 50  # max mpg is 46.6\n",
    "    return Tclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 398 rows and 8 columns from auto-mpg.data\n",
      "After removing rows containing question marks, data has 392 rows and 8 columns.\n",
      "classes [15 25 35 50]\n",
      "counts [ 69 167 123  33]\n"
     ]
    }
   ],
   "source": [
    "X,T,Xnames,Tname = makeMPGData('auto-mpg.data')\n",
    "Tclasses = makeMPGClasses(T)\n",
    "classes,counts = np.unique(Tclasses,return_counts=True)\n",
    "print('classes',classes)\n",
    "print('counts',counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printResults(label,results):\n",
    "    print('{:4s} {:>20s}{:>8s}{:>8s}{:>8s}'.format('Algo','Parameters','TrnAcc','ValAcc','TesAcc'))\n",
    "    print('-------------------------------------------------')\n",
    "    for row in results:\n",
    "        # 20 is expected maximvl um number of characters in printed parameter value list\n",
    "        print('{:>4s} {:>20s} {:7.2f} {:7.2f} {:7.2f}'.format(label,str(row[0]),*row[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/s/bach/k/under/xuehaohu/cs480/A4/A4grader.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m resultsLDA = ml.trainValidateTestKFoldsClassification( trainLDA,evaluateLDA, X,Tclasses, [None],\n\u001b[1;32m----> 2\u001b[1;33m                                                        nFolds=6, shuffle=False,verbose=False)\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprintResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LDA:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresultsLDA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/s/bach/k/under/xuehaohu/cs480/A4/mlutils.py\u001b[0m in \u001b[0;36mtrainValidateTestKFoldsClassification\u001b[1;34m(trainf, evaluatef, X, T, parameterSets, nFolds, shuffle, verbose)\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[0mvalidateAccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluatef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTvalidate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mvalidateAccuracySum\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mvalidateAccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test Fold {}, Parms {}, Validate Fold {} and Accuracy {:.2f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestFold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidateFold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidateAccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "resultsLDA = ml.trainValidateTestKFoldsClassification( trainLDA,evaluateLDA, X,Tclasses, [None],\n",
    "                                                       nFolds=6, shuffle=False,verbose=False)\n",
    "printResults('LDA:',resultsLDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultsQDA = ml.trainValidateTestKFoldsClassification( trainQDA,evaluateQDA, X,Tclasses, [None],\n",
    "                                                        nFolds=6, shuffle=False,verbose=False)\n",
    "printResults('QDA:',resultsQDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultsNN = ml.trainValidateTestKFoldsClassification( trainNN,evaluateNN, X,Tclasses, \n",
    "                                                     [ [ [0], 10], [[10], 100] ],\n",
    "                                                     nFolds=6, shuffle=False,verbose=False)\n",
    "printResults('NN:',resultsNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda = ql.LDA()\n",
    "lda.train(X,Tclasses)\n",
    "predictedClasses,_,_ = lda.use(X)\n",
    "ml.confusionMatrix(Tclasses,predictedClasses,classes); # <- semi-colon prevents printing of returned result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Pick at least two classification data sets and apply LDA, QDA, Linear Logistic Regression and Nonlinear Logistic Regression to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "In this section, we will be looking for\n",
    "\n",
    "* clear explanations of each function;\n",
    "* experiments with two different data sets with descriptions of the data;\n",
    "* and discussion of each result, including\n",
    "  * accuracies as percent correctly classified,\n",
    "  * best parameter values,\n",
    "  * some analysis of each classification algorithm and how it is classifying the data by examining the $\\mu$ values for LDA and QDA, and the first layer's weight values for the neural networks;\n",
    "* and discuss which algorithm works best for each data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "Your notebook will be run and graded automatically. Download [A4grader.tar](http://www.cs.colostate.edu/~anderson/cs480/notebooks/A4grader.tar)  and extract A4grader.py from it. Run the code in the following cell to demonstrate an example grading session. You should see a perfect score of 80/100 if your functions are defined correctly. \n",
    "\n",
    "The remaining 20% will be based on your writing.  Be sure to explain each function, and details of the results summarized in the above section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check-in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not include this section in your notebook.\n",
    "\n",
    "Name your notebook ```Lastname A4.ipynb```.  So, for me it would be ```Anderson A4.ipynb```.  Submit the file using the ```Assignment 4``` link on [Canvas](https://colostate.instructure.com/courses/28803).\n",
    "\n",
    "Grading will be based on \n",
    "\n",
    "  * correct behavior of the required functions,\n",
    "  * readability of the notebook,\n",
    "  * effort in making interesting observations, and in formatting your notebook,\n",
    "  * testing your code on two different classification data sets of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run -i A4grader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
